# Transformer

This is a GPT build based on the paper "Attention is All You Need", OpenAI's GPT-2 / GPT-3, and Andrej Karpathy's lecture on building transformers from scratch. It is able to display character-level predictions for text in the manner of Shakespeare, and the dataset that I used is tiny shakespeare: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt

# Links
- Attention Is All You Need: https://arxiv.org/pdf/1706.03762.pdf
- nanoGPT repo: https://github.com/karpathy/nanoGPT
- Andrej Karpathy's Transformer Video: https://www.youtube.com/watch?v=kCc8FmEb1nY
- Video repo: https://github.com/karpathy/ng-video-lecture
- Video Google colab: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing
