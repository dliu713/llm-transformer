# Transformer

This is a GPT build based on the paper "Attention is All You Need" and Andrej Karpathy's lecture on building transformers from scratch. It is able to display character-level predictions for text in the manner of Shakespeare, and the dataset that I used is tiny shakespeare: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt

- Run: $ python shakespeare_gpt.py > output.txt
- Workbook: transformer.ipynb
- Self-attention crux: under_the_hood.txt

# Resources
- Attention Is All You Need: https://arxiv.org/pdf/1706.03762.pdf
- nanoGPT repo: https://github.com/karpathy/nanoGPT
- Andrej Karpathy's Transformer Video: https://www.youtube.com/watch?v=kCc8FmEb1nY
- Video repo: https://github.com/karpathy/ng-video-lecture
- Video Google colab: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing
